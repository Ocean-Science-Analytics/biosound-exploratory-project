<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>BioSound Exploratory Project - Acoustic-Based Biodiversity Indices</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./indices.html">Acoustic Indices</a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
      <a href="./index.html" class="sidebar-logo-link">
      <img src="./images/BioSound.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Project Overview</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./indices.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Acoustic Indices</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Processing &amp; Management</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Evaluating Indices</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./recommendations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Recommendations</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#soundscape-metrics" id="toc-soundscape-metrics" class="nav-link active" data-scroll-target="#soundscape-metrics">Soundscape Metrics</a></li>
  <li><a href="#acoustic-based-biodiversity-indices" id="toc-acoustic-based-biodiversity-indices" class="nav-link" data-scroll-target="#acoustic-based-biodiversity-indices">Acoustic-based Biodiversity Indices</a></li>
  <li><a href="#index-definitions" id="toc-index-definitions" class="nav-link" data-scroll-target="#index-definitions">Index Definitions</a></li>
  <li><a href="#frequency-bands-thresholds-masks" id="toc-frequency-bands-thresholds-masks" class="nav-link" data-scroll-target="#frequency-bands-thresholds-masks">Frequency Bands, Thresholds &amp; Masks</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Acoustic-Based Biodiversity Indices</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="soundscape-metrics" class="level3">
<h3 class="anchored" data-anchor-id="soundscape-metrics">Soundscape Metrics</h3>
<p>Soundscape measurements refer to the quantitative analysis of the sounds present in a particular environment, capturing not only individual sounds but also their patterns, frequencies, and intensities over time. These measurements are important in relation to biodiversity indices for several reasons:</p>
<ol type="1">
<li><p><strong>Indicator of Biodiversity</strong>: The diversity and composition of species within an ecosystem can be inferred from the soundscape. Different species produce distinct sounds, and the presence or absence of certain sounds can indicate the presence or absence of particular species. For example, the diversity of bird calls in a forest can be used as an indicator of avian biodiversity.</p></li>
<li><p><strong>Non-invasive Monitoring</strong>: Soundscape measurements offer a non-invasive way to monitor biodiversity. Unlike traditional methods such as trapping or visual surveys, which can be disruptive and time-consuming, recording and analyzing soundscape data can be done remotely and continuously, providing valuable insights into biodiversity without disturbing the ecosystem.</p></li>
<li><p><strong>Temporal and Spatial Dynamics</strong>: Soundscape measurements capture the temporal and spatial dynamics of biodiversity. By analyzing changes in sound patterns and intensity over time and across different locations within an ecosystem, researchers can identify patterns of species activity, migration, and distribution, providing a more comprehensive understanding of biodiversity dynamics.</p></li>
<li><p><strong>Early Warning System</strong>: Changes in the soundscape can serve as an early warning system for ecosystem health. Alterations in sound patterns, such as the decline or disappearance of certain species’ vocalizations, can indicate disturbances or threats to biodiversity, such as habitat loss, pollution, or invasive species encroachment, allowing for timely intervention and conservation efforts.</p></li>
<li><p><strong>Integration with Biodiversity Indices</strong>: Soundscape measurements can be integrated with traditional biodiversity indices to enhance their accuracy and comprehensiveness. By combining acoustic data with other ecological data, such as species abundance and habitat characteristics, researchers can develop more robust biodiversity assessments that capture the full spectrum of biodiversity within an ecosystem.</p></li>
</ol>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="images/Underwater_Acoustics.png" class="img-fluid quarto-figure quarto-figure-left figure-img" width="288"></p>
</figure>
</div>
<hr>
</section>
<section id="acoustic-based-biodiversity-indices" class="level3">
<h3 class="anchored" data-anchor-id="acoustic-based-biodiversity-indices">Acoustic-based Biodiversity Indices</h3>
<p>For this exploratory study we use the package scikit-maad, a tool commonly used in the terrestrial community. <a href="https://scikit-maad.github.io/#">Scikit-maad</a>, short for “Machine learning for Acoustic Activity Detection,” is a Python package designed for the analysis of acoustic data, particularly for bioacoustic applications. It provides a comprehensive set of tools and functions for processing, extracting features from, and analyzing soundscape recordings. Scikit-maad is primarily focused on facilitating the use of machine learning techniques for tasks such as acoustic event detection, species classification, and biodiversity monitoring.</p>
<p>The developers of scikit-maad are a team of researchers and developers passionate about bioacoustics and computational ecology. They have expertise in signal processing, machine learning, and ecology, and their aim is to provide accessible and powerful tools for analyzing acoustic data and advancing research in the field of bioacoustics. The development of scikit-maad is supported by contributions from the open-source community and collaborations with researchers and practitioners in various domains related to acoustic ecology and biodiversity monitoring.</p>
<p>In scikit-maad, the acoustic-based indices can be categorized into several main categories based on the aspects of the acoustic signal they capture:</p>
<ol type="1">
<li><p><strong>Temporal Indices</strong>: These indices focus on the temporal characteristics of the acoustic signal, such as event duration, inter-event intervals, and event rate.</p></li>
<li><p><strong>Spectral Indices</strong>: These indices analyze the frequency content of the acoustic signal, including measures such as spectral flux, spectral centroid, and mel-frequency cepstral coefficients (MFCC).</p></li>
<li><p><strong>Spectro-Temporal Indices</strong>: These indices combine both temporal and spectral features, capturing information about the dynamics and variability of the acoustic signal over time and across different frequency bands.</p></li>
<li><p><strong>Alpha Acoustic Indices</strong>: These indices are derived from ecological concepts and are specifically designed to quantify aspects of biodiversity or acoustic activity within a given environment. Examples include the Acoustic Diversity Index (ADI), Acoustic Complexity Index (ACI), and Acoustic Richness Index (ARI).</p></li>
</ol>
<hr>
</section>
<section id="index-definitions" class="level3">
<h3 class="anchored" data-anchor-id="index-definitions">Index Definitions</h3>
<p>Below is a summary of the available spectro-temporal features, alpha acoustic indices, temporal features, and spectral features in scikit-maad:</p>
<p><strong>ACI (Acoustic Complexity Index)</strong></p>
<ul>
<li><p><strong>Description</strong>: Quantifies the complexity of sound by evaluating the variation in amplitude among frequency bands.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-3178511736.png" class="img-fluid" width="287"></p></li>
</ul>
<p><strong>ADI (Acoustic Diversity Index)</strong></p>
<ul>
<li><p><strong>Description</strong>: Measures the variety of sound frequencies present, indicative of biodiversity.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-3670162486.png" class="img-fluid" width="439">frequency bin.</p></li>
</ul>
<p><strong>AEI (Acoustic Evenness Index)</strong></p>
<ul>
<li><p><strong>Description</strong>: Evaluates the evenness of the distribution of sound energy across frequencies.</p></li>
<li><p><strong>Formula</strong>: Similar to ecological evenness indices, calculated as AEI=<img src="images/clipboard-224518301.png" class="img-fluid" width="200"></p></li>
</ul>
<p><strong>ACTspCount (Active Space Count)</strong></p>
<ul>
<li><p><strong>Description</strong>: Count of spatial areas showing significant sound activity.</p></li>
<li><p><strong>Formula</strong>: Counting areas where sound exceeds a certain spatial or acoustic threshold.</p></li>
</ul>
<p><strong>ACTspFract (Active Space Fraction)</strong></p>
<ul>
<li><p><strong>Description</strong>: Fraction of the spatial domain showing active sound production.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-184378821.png" class="img-fluid" width="304"></p></li>
</ul>
<p><strong>ACTspMean (Active Space Mean)</strong></p>
<ul>
<li><p><strong>Description</strong>: Average level of sound activity across spatial areas.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-3492482506.png" width="405" height="38"></p></li>
</ul>
<p><strong>ACTtCount (Active Time Count)</strong></p>
<ul>
<li><p><strong>Description</strong>: Number of times the sound level exceeds the predefined threshold.</p></li>
<li><p><strong>Formula</strong>: Counting the number of active frames.</p></li>
</ul>
<p><strong>ACTtFraction (Active Time Fraction)</strong></p>
<ul>
<li><p><strong>Description</strong>: Proportion of the recording duration where the sound level exceeds a predefined threshold.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-537697800.png" class="img-fluid" width="271"></p></li>
</ul>
<p><strong>ACTtMean (Active Time Mean)</strong></p>
<ul>
<li><p><strong>Description</strong>: Average sound level during active times.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-1754306291.png" class="img-fluid" width="416"></p></li>
</ul>
<p><strong>AGI (Acoustic Gap Index)</strong></p>
<ul>
<li><p><strong>Description</strong>: Index measuring the gaps or silent intervals within the acoustic signal, indicative of disturbance.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-4223693148.png" class="img-fluid" width="230"></p></li>
</ul>
<p><strong>AnthroEnergy (Anthropogenic Energy)</strong></p>
<ul>
<li><p><strong>Description</strong>: Measure of energy associated with human-made sounds.</p></li>
<li><p><strong>Formula</strong>: Sum of energy in designated anthropogenic frequency bands.</p></li>
</ul>
<p><strong>BGNf (Background Noise Level Frequency)</strong></p>
<ul>
<li><p><strong>Description</strong>: Background noise level in the frequency domain.</p></li>
<li><p><strong>Formula</strong>: Typically estimated during periods of minimal activity; specifics can vary.</p></li>
</ul>
<p><strong>BGNt (Background Noise Level Time)</strong></p>
<ul>
<li><p><strong>Description</strong>: Level of background noise in the time domain.</p></li>
<li><p><strong>Formula</strong>: Typically estimated during periods of minimal activity; specifics can vary.</p></li>
</ul>
<p><strong>BI (Biotic Index)</strong></p>
<ul>
<li><p><strong>Description</strong>: Index evaluating the presence of biological sounds.</p></li>
<li><p><strong>Formula</strong>: Calculated as a function of specific frequency and time thresholds indicative of biological activity.</p></li>
</ul>
<p><strong>BioEnergy (Biophonic Energy)</strong></p>
<ul>
<li><p><strong>Description</strong>: Measure of energy associated with natural sounds.</p></li>
<li><p><strong>Formula</strong>: Sum of energy in designated biophonic frequency bands.</p></li>
</ul>
<p><strong>EAS (Energy Acoustic Spectrum)</strong></p>
<ul>
<li><p><strong>Description</strong>: Total acoustic energy measured across the spectrum.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-3224557143.png" class="img-fluid" width="192"></p></li>
</ul>
<p><strong>ECU (Evenness of the Channel Utilization)</strong></p>
<ul>
<li><p><strong>Description</strong>: Evenness with which different frequency channels are utilized.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-3100385703.png" class="img-fluid" width="267"></p></li>
</ul>
<p><strong>ECV (Energy Coefficient of Variation)</strong></p>
<ul>
<li><p><strong>Description</strong>: Coefficient of variation of the energy across different frequency bands.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-1523706811.png" class="img-fluid" width="153">​​</p></li>
</ul>
<p><strong>ENRf (Energy Ratio Frequency)</strong></p>
<ul>
<li><p><strong>Description</strong>: Ratio of energy within certain frequency bands compared to the total energy.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-1730251621.png" class="img-fluid" width="233"></p></li>
</ul>
<p><strong>EPS (Energy Peak Spectrum)</strong></p>
<ul>
<li><p><strong>Description</strong>: Measure of the peak energy in the spectrum.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-539386795.png" class="img-fluid" width="220"></p></li>
</ul>
<p><strong>EPS_KURT (Energy Peak Spectrum Kurtosis)</strong></p>
<ul>
<li><p><strong>Description</strong>: Kurtosis of the energy peak spectrum, indicating the shape of the peak distribution.</p></li>
<li><p><strong>Formula</strong>: Calculation of kurtosis applied to the distribution of peak energies.</p></li>
</ul>
<p><strong>EPS_SKEW (Energy Peak Spectrum Skewness)</strong></p>
<ul>
<li><p><strong>Description</strong>: Skewness of the energy peak spectrum, indicating the asymmetry of the peak distribution.</p></li>
<li><p><strong>Formula</strong>: Calculation of skewness applied to the distribution of peak energies.</p></li>
</ul>
<p><strong>EVNspCount (Event Space Count)</strong></p>
<ul>
<li><p><strong>Description</strong>: Count of sound events in spatial areas.</p></li>
<li><p><strong>Formula</strong>: Counting distinct sound events in spatial regions.</p></li>
</ul>
<p><strong>EVNspFract (Event Space Fraction)</strong></p>
<ul>
<li><p><strong>Description</strong>: Fraction of the spatial domain where sound events occur.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-1013212438.png" class="img-fluid" width="337"></p></li>
</ul>
<p><strong>EVNspMean (Event Space Mean)</strong></p>
<ul>
<li><p><strong>Description</strong>: Average level of sound events across spatial areas.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-1164138196.png" class="img-fluid" width="491"></p></li>
</ul>
<p><strong>EVNtCount (Event Time Count)</strong></p>
<ul>
<li><p><strong>Description</strong>: Number of distinct sound events detected.</p></li>
<li><p><strong>Formula</strong>: Counting distinct events based on a defined threshold.</p></li>
</ul>
<p><strong>EVNtFraction (Event Time Fraction)</strong></p>
<ul>
<li><p><strong>Description</strong>: Fraction of time that ‘events’ (heightened sound activity) occur.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-3332730601.png" class="img-fluid" width="296"></p></li>
</ul>
<p><strong>EVNtMean (Event Time Mean)</strong></p>
<ul>
<li><p><strong>Description</strong>: Average sound level during event times.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-3284712092.png" class="img-fluid" width="406"></p></li>
</ul>
<p><strong>Hf (High Frequency Coverage)</strong></p>
<ul>
<li><p><strong>Description</strong>: Extent to which high frequencies are present in the soundscape.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-2523022695.png" class="img-fluid" width="341"></p></li>
</ul>
<p><strong>HFC (High Frequency Coverage)</strong></p>
<ul>
<li><p><strong>Description</strong>: Reiterates the presence and extent of high frequencies in the soundscape.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-1761188340.png" class="img-fluid" width="316"></p></li>
</ul>
<p><strong>H_GiniSimpson (Gini-Simpson Entropy)</strong></p>
<ul>
<li><p><strong>Description</strong>: Entropy based on the Gini-Simpson index, reflecting diversity and probability.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-961694826.png" class="img-fluid"></p></li>
</ul>
<p><strong>H_Havrda (Havrda Entropy)</strong></p>
<ul>
<li><p><strong>Description</strong>: Entropy measure based on Havrda-Charvat entropy, reflecting diversity.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-605951696.png" class="img-fluid"></p></li>
</ul>
<p><strong>H_pairedShannon (Paired Shannon Entropy)</strong></p>
<ul>
<li><p><strong>Description</strong>: Shannon entropy calculated from paired data sets for comparing diversity.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-1644268972.png" class="img-fluid"></p></li>
</ul>
<p><strong>H_Renyi (Renyi Entropy)</strong></p>
<ul>
<li><p><strong>Description</strong>: Generalized entropy measure capturing diversity and richness of the soundscape.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-1152059287.png" class="img-fluid"></p></li>
</ul>
<p><strong>H_gamma (Gamma Entropy)</strong></p>
<ul>
<li><p><strong>Description</strong>: Entropy measure based on the gamma distribution, used for sound diversity.</p></li>
<li><p><strong>Formula</strong>: Specific calculation details can vary, often involving the use of the gamma function in entropy calculations.</p></li>
</ul>
<p><strong>KURTf (Kurtosis Frequency)</strong></p>
<ul>
<li><p><strong>Description</strong>: ‘Tailedness’ of the frequency distribution, indicating infrequent extreme frequency deviations.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-126612138.png" class="img-fluid" width="314"></p></li>
</ul>
<p><strong>KURTt (Kurtosis Time)</strong></p>
<ul>
<li><p><strong>Description</strong>: ‘Tailedness’ of the amplitude distribution in the time domain, indicating infrequent extreme deviations.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-3987843613.png" class="img-fluid" width="323"></p></li>
</ul>
<p><strong>LFC (Low Frequency Coverage)</strong></p>
<ul>
<li><p><strong>Description</strong>: Extent to which low frequencies are present in the soundscape.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-3361057686.png" class="img-fluid" width="346"></p></li>
</ul>
<p><strong>LEQf (Long-term Equivalent Level Frequency)</strong></p>
<ul>
<li><p><strong>Description</strong>: Equivalent constant sound level in the frequency domain that conveys the same sound energy.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-2676081756.png" class="img-fluid" width="319"></p></li>
</ul>
<p><strong>LEQt (Long-term Equivalent Level Time)</strong></p>
<ul>
<li><p><strong>Description</strong>: Constant sound level that delivers the same sound energy as the varying sound level over a specified period.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-494037990.png" class="img-fluid" width="326"></p></li>
</ul>
<p><strong>MFC (Mid Frequency Coverage)</strong></p>
<ul>
<li><p><strong>Description</strong>: Extent to which mid-range frequencies are present in the soundscape.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-4213737357.png" class="img-fluid" width="303"></p></li>
</ul>
<p><strong>MEANf (Mean Frequency)</strong></p>
<ul>
<li><p><strong>Description</strong>: Average frequency of sounds, weighted by their amplitude.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-2415357253.png" class="img-fluid" width="194"></p></li>
</ul>
<p><strong>MEANt (Mean Time)</strong></p>
<ul>
<li><p><strong>Description</strong>: The average amplitude of the audio signal over time, reflecting the overall loudness.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-733360590.png" class="img-fluid" width="251"></p></li>
</ul>
<p><strong>NBPEAKS (Number of Peaks)</strong></p>
<ul>
<li><p><strong>Description</strong>: Total number of prominent peaks in the frequency spectrum.</p></li>
<li><p><strong>Formula</strong>: Count of frequency peaks exceeding a certain amplitude threshold.</p></li>
</ul>
<p><strong>NDSI (Normalized Difference Soundscape Index)</strong></p>
<ul>
<li><p><strong>Description</strong>: Index of the balance between biological sounds and anthropogenic noise.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-3621976947.png" class="img-fluid" width="139"></p></li>
</ul>
<p><strong>RAOQ (Rao’s Quadratic Entropy)</strong></p>
<ul>
<li><p><strong>Description</strong>: Entropy measure that considers both abundance and dissimilarity among categories.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-575858343.png" class="img-fluid" width="280">​</p></li>
</ul>
<p><strong>rBA (Relative Biophony-Anthrophony)</strong></p>
<ul>
<li><p><strong>Description</strong>: Relative levels of biophony (natural sounds) and anthrophony (human-made sounds).</p></li>
<li><p><strong>Formula</strong>: Similar to NDSI, calculated for different contexts or specific frequency bands.</p></li>
</ul>
<p><strong>ROIcover (Region of Interest Coverage)</strong></p>
<ul>
<li><p><strong>Description</strong>: Extent to which regions of interest cover the acoustic space.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-1902297317.png" class="img-fluid" width="275">​</p></li>
</ul>
<p><strong>ROItotal (Region of Interest Total)</strong></p>
<ul>
<li><p><strong>Description</strong>: Total measure or count of regions of interest identified within the soundscape.</p></li>
<li><p><strong>Formula</strong>: Counting the total number of identified acoustic regions of interest.</p></li>
</ul>
<p><strong>ROU (Roughness)</strong></p>
<ul>
<li><p><strong>Description</strong>: Measure of the texture or roughness of the sound profile.</p></li>
<li><p><strong>Formula</strong>: Typically involves calculating modulation of sound amplitude or frequency over time.</p></li>
</ul>
<p><strong>SKEWf (Skewness Frequency)</strong></p>
<ul>
<li><p><strong>Description</strong>: Asymmetry of the frequency distribution of the sound.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-2731961336.png" class="img-fluid" width="319"></p></li>
</ul>
<p><strong>SKEWt (Skewness Time)</strong></p>
<ul>
<li><p><strong>Description</strong>: Asymmetry of the amplitude distribution of the audio signal in the time domain.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-2056538908.png" class="img-fluid"></p></li>
</ul>
<p><strong>SNRf (Signal-to-Noise Ratio Frequency)</strong></p>
<ul>
<li><p><strong>Description</strong>: Ratio of signal level to noise level in the frequency domain.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-1762060253.png" class="img-fluid" width="338"></p></li>
</ul>
<p><strong>SNRt (Signal-to-Noise Ratio Time)</strong></p>
<ul>
<li><p><strong>Description</strong>: Ratio of the audio signal level to the level of background noise.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-3194904740.png" class="img-fluid" width="253"></p></li>
</ul>
<p><strong>TFSD (Temporal Frequency Spectral Diversity)</strong></p>
<ul>
<li><p><strong>Description</strong>: Diversity of frequencies over time, reflecting temporal variation.</p></li>
<li><p><strong>Formula</strong>: Often calculated using indices similar to biodiversity indices but applied to the temporal frequency spectrum.</p></li>
</ul>
<p><strong>VARf (Variance Frequency)</strong></p>
<ul>
<li><p><strong>Description</strong>: Variance in the frequency of sounds, indicating dispersion around the mean frequency.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-2364587936.png" class="img-fluid" width="236"></p></li>
</ul>
<p><strong>VARt (Variance Time)</strong></p>
<ul>
<li><p><strong>Description</strong>: Variance of the time-domain audio signal amplitude, indicating amplitude fluctuations over time.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-725325231.png" class="img-fluid" width="265"></p></li>
</ul>
<p><strong>ZCR (Zero Crossing Rate)</strong></p>
<ul>
<li><p><strong>Description</strong>: Measures the rate at which the signal changes from positive to negative or back, indicating the frequency content of the sound.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-4119730632.png" class="img-fluid" width="335"></p></li>
</ul>
<hr>
</section>
<section id="frequency-bands-thresholds-masks" class="level3">
<h3 class="anchored" data-anchor-id="frequency-bands-thresholds-masks">Frequency Bands, Thresholds &amp; Masks</h3>
<section id="indices-measuring-biophony-vs.-anthrophony" class="level4">
<h4 class="anchored" data-anchor-id="indices-measuring-biophony-vs.-anthrophony"><em>Indices Measuring Biophony vs.&nbsp;Anthrophony</em></h4>
<ol type="1">
<li><p><strong>NDSI (Normalized Difference Soundscape Index)</strong></p>
<ul>
<li><p><strong>Description</strong>: Quantifies the balance between biophonic and anthrophonic sound sources within a soundscape. It is often used as a metric for assessing environmental health and biodiversity.</p></li>
<li><p><strong>Formula</strong>: <img src="images/clipboard-778764244.png" class="img-fluid"></p>
<ul>
<li><p>B: Biophony energy within defined frequency bands.</p></li>
<li><p>A: Anthrophony energy within defined frequency bands.</p></li>
</ul></li>
<li><p><strong>Frequency Limits</strong>:</p>
<ul>
<li><p><strong>Biophony</strong>: Typically low to mid frequencies (e.g., 0-1000 Hz).</p></li>
<li><p><strong>Anthrophony</strong>: Typically higher frequencies (e.g., 1000-4000 Hz).</p></li>
</ul></li>
</ul></li>
<li><p><strong>BioEnergy (Biophonic Energy)</strong></p>
<ul>
<li><p><strong>Description</strong>: Measures the total acoustic energy attributed to natural sound sources within the defined biophonic frequency range.</p></li>
<li><p><strong>Calculation</strong>: Sum of the acoustic energy in the biophonic frequency bands.</p></li>
<li><p><strong>Frequency Limits</strong>:</p>
<ul>
<li><strong>Biophony</strong>: Typically low frequencies (e.g., 0-1000 Hz).</li>
</ul></li>
</ul></li>
<li><p><strong>AnthroEnergy (Anthropogenic Energy)</strong></p>
<ul>
<li><p><strong>Description</strong>: Measures the total acoustic energy attributed to human-made sound sources within the defined anthrophonic frequency range.</p></li>
<li><p><strong>Calculation</strong>: Sum of the acoustic energy in the anthrophonic frequency bands.</p></li>
<li><p><strong>Frequency Limits</strong>:</p>
<ul>
<li><strong>Anthrophony</strong>: Typically higher frequencies (e.g., 1000-4000 Hz).</li>
</ul></li>
</ul></li>
<li><p><strong>rBA (Relative Biophony-Anthrophony)</strong></p>
<ul>
<li><p><strong>Description</strong>: Compares the relative levels of biophonic and anthrophonic energy within the soundscape.</p></li>
<li><p><strong>Calculation</strong>: A ratio or comparison metric between the biophonic and anthrophonic energies.</p></li>
<li><p><strong>Frequency Limits</strong>:</p>
<ul>
<li><p><strong>Biophony</strong>: Typically low frequencies (e.g., 0-1000 Hz).</p></li>
<li><p><strong>Anthrophony</strong>: Typically higher frequencies (e.g., 1000-4000 Hz).</p></li>
</ul></li>
</ul></li>
</ol>
<p>In addition to the indices that explicitly measure biophony and anthrophony (like NDSI, BioEnergy, AnthroEnergy, and rBA), there are other indices in the <code>scikit-maad</code> library that utilize these frequency limits (<code>flim_low</code> and <code>flim_mid</code>) for their calculations. Here are some additional indices that rely on these frequency bands:</p>
<ol type="1">
<li><p><strong>BI (Biotic Index)</strong></p>
<ul>
<li><p><strong>Description</strong>: Measures the presence and intensity of biotic sounds within the biophonic frequency range.</p></li>
<li><p><strong>Frequency Limits</strong>:</p>
<ul>
<li><strong>Biophony</strong>: Typically low frequencies (e.g., 0-1000 Hz).</li>
</ul></li>
</ul></li>
<li><p><strong>ACI (Acoustic Complexity Index)</strong></p>
<ul>
<li><p><strong>Description</strong>: Quantifies the complexity of the soundscape by evaluating the variation in amplitude among frequency bands over time.</p></li>
<li><p><strong>Frequency Limits</strong>: The index can be applied to specific frequency bands, often including the biophonic and anthrophonic ranges.</p>
<ul>
<li><p><strong>Biophony</strong>: 0-1000 Hz.</p></li>
<li><p><strong>Anthrophony</strong>: 1000-4000 Hz.</p></li>
</ul></li>
</ul></li>
<li><p><strong>EPS (Energy Peak Spectrum)</strong></p>
<ul>
<li><p><strong>Description</strong>: Measures the peak energy in the spectrum within specified frequency bands.</p></li>
<li><p><strong>Frequency Limits</strong>: Can be calculated separately for biophony and anthrophony bands.</p>
<ul>
<li><p><strong>Biophony</strong>: 0-1000 Hz.</p></li>
<li><p><strong>Anthrophony</strong>: 1000-4000 Hz.</p></li>
</ul></li>
</ul></li>
<li><p><strong>ROU (Roughness)</strong></p>
<ul>
<li><p><strong>Description</strong>: Evaluates the texture or roughness of the sound profile, which can be calculated for different frequency bands.</p></li>
<li><p><strong>Frequency Limits</strong>:</p>
<ul>
<li><p><strong>Biophony</strong>: 0-1000 Hz.</p></li>
<li><p><strong>Anthrophony</strong>: 1000-4000 Hz.</p></li>
</ul></li>
</ul></li>
<li><p><strong>ADI (Acoustic Diversity Index)</strong></p>
<ul>
<li><p><strong>Description</strong>: Measures the variety of sound frequencies present, indicative of biodiversity.</p></li>
<li><p><strong>Frequency Limits</strong>: Applied across biophony and anthrophony bands to assess diversity in each.</p>
<ul>
<li><p><strong>Biophony</strong>: 0-1000 Hz.</p></li>
<li><p><strong>Anthrophony</strong>: 1000-4000 Hz.</p></li>
</ul></li>
</ul></li>
<li><p><strong>AEI (Acoustic Evenness Index)</strong></p>
<ul>
<li><p><strong>Description</strong>: Evaluates the evenness of the distribution of sound energy across frequencies, which can be applied to specific bands.</p></li>
<li><p><strong>Frequency Limits</strong>:</p>
<ul>
<li><p><strong>Biophony</strong>: 0-1000 Hz.</p></li>
<li><p><strong>Anthrophony</strong>: 1000-4000 Hz.</p></li>
</ul></li>
</ul></li>
</ol>
</section>
<section id="frequency-band-details" class="level4">
<h4 class="anchored" data-anchor-id="frequency-band-details"><em>Frequency Band Details</em></h4>
<p>The differentiation between biophony and anthrophony is critical for accurately interpreting these indices. Here’s how these limits are typically set in the <code>scikit-maad</code> functions:</p>
<ul>
<li><p><strong>Biophony (Natural Sounds)</strong>:</p>
<ul>
<li>Frequency bands often range from <strong>0 Hz to 1000 Hz</strong>. This range captures most natural sounds such as bird calls, frog croaks, and other wildlife communications.</li>
</ul></li>
<li><p><strong>Anthrophony (Human-made Sounds)</strong>:</p>
<ul>
<li>Frequency bands often range from <strong>1000 Hz to 4000 Hz</strong>. This range includes many anthropogenic noises like machinery, vehicles, and urban sounds.</li>
</ul></li>
</ul>
<p><strong>Example Code for Frequency Limits in <code>scikit-maad</code></strong></p>
<p>Here’s how these frequency limits are typically applied in the <code>scikit-maad</code> functions:</p>
<pre class="{python}}"><code>spectral_indices, spectral_indices_per_bin = features.all_spectral_alpha_indices(
    Sxx_power=Sxx_power,
    tn=tn,
    fn=fn,
    flim_low=[0, 1000],    # Frequency band for biophony
    flim_mid=[1000, 4000], # Frequency band for anthrophony
    flim_hi=[4000, 8000],  # Higher frequencies if needed
    gain=G,
    sensitivity=S,
    verbose=False,
    R_compatible='soundecology',
    mask_param1=6, 
    mask_param2=0.5,
    display=False
)
</code></pre>
</section>
<section id="thresholds-and-masks-in-scikit-maad" class="level4">
<h4 class="anchored" data-anchor-id="thresholds-and-masks-in-scikit-maad">Thresholds and Masks in <code>scikit-maad</code></h4>
<ol type="1">
<li><p><strong>dB_threshold</strong></p>
<p><strong>Description</strong>: This threshold is used to determine active segments in the audio signal. It sets the minimum amplitude level that must be exceeded for a segment to be considered active.</p>
<ul>
<li><p><strong>Use Case</strong>: Applied in the calculation of temporal indices like <code>ACTtCount</code>, <code>ACTtFraction</code>, and other active time metrics.</p></li>
<li><p><strong>Parameters</strong>:</p>
<ul>
<li><strong>dB_threshold</strong>: 3 dB # Minimum amplitude level for active segments</li>
</ul></li>
<li><p><strong>Example in Code</strong></p></li>
</ul></li>
</ol>
<pre class="{python}}"><code>temporal_indices = features.all_temporal_alpha_indices(
    s=segment_wave,
    fs=fs,
    gain=G,
    sensibility=S,
    dB_threshold=3,  # This is the threshold defined in decibels
    rejectDuration=0.01,
    verbose=False,
    display=False
)
</code></pre>
<ol start="2" type="1">
<li><p><strong>mask_param1</strong></p>
<p><strong>Description</strong>: This parameter is typically used as a threshold in decimbels for masking low-energy components in the spectrogram. Any part of the spectrogram with energy below this threshold might be set to zero or ignored in further calculations.</p>
<ul>
<li><p><strong>Use Case</strong>: Used in spectral analysis to filter out noise and irrelevant low-energy componenets.</p></li>
<li><p><strong>Parameters</strong>: <strong>mask_param1</strong>: 6 dB # Threshold for masking low-energy components in the spectrogram</p></li>
<li><p><strong>Example in Code:</strong></p>
<pre class="{python}}"><code>spectral_indices, spectral_indices_per_bin = features.all_spectral_alpha_indices(
    Sxx_power=Sxx_power,
    tn=tn,
    fn=fn,
    flim_low=[0, 1000],
    flim_mid=[1000, 4000],
    flim_hi=[4000, 8000],
    gain=G,
    sensitivity=S,
    verbose=False,
    R_compatible='soundecology',
    mask_param1=6,  # This is the threshold for masking in decibels
    mask_param2=0.5,
    display=False
)
</code></pre></li>
</ul></li>
<li><p><strong>mask_param2</strong></p>
<p><strong>Description</strong>: This parameter might determine the sensitivity or proportion of the masking process, influencing how aggressively the mask is applied.</p>
<ul>
<li><p><strong>Use Case</strong>: Used alongside <code>mask_param1</code> to refine the masking process in spectral analysis.</p></li>
<li><p><strong>Parameters</strong>: <strong>mask_param2</strong>: 0.5 # Sensitivity or proportion parameter for the masking process</p></li>
</ul></li>
</ol>
<p><strong>Example code</strong></p>
<pre class="{python}}"><code>spectral_indices, spectral_indices_per_bin = features.all_spectral_alpha_indices(
    Sxx_power=Sxx_power,
    tn=tn,
    fn=fn,
    flim_low=[0, 1000],
    flim_mid=[1000, 4000],
    flim_hi=[4000, 8000],
    gain=G,
    sensitivity=S,
    verbose=False,
    R_compatible='soundecology',
    mask_param1=6,
    mask_param2=0.5,  # This is the sensitivity parameter for the mask
    display=False
)
</code></pre>
<p>These parameters affect a suite of indices, and so users should consider the intended spectral components they are interested in exploring.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>